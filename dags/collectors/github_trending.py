"""
GitHub Trending í¬ë¡¤ëŸ¬
"""
import requests
from bs4 import BeautifulSoup
from typing import List, Dict
import time


def scrape_github_trending(language: str = "", limit: int = 10) -> List[Dict]:
    """
    GitHub Trending í˜ì´ì§€ì—ì„œ íŠ¸ë Œë”© ë ˆí¬ì§€í† ë¦¬ í¬ë¡¤ë§

    Args:
        language: í”„ë¡œê·¸ë˜ë° ì–¸ì–´ í•„í„° (ì˜ˆ: 'python', 'javascript', '')
        limit: ê°€ì ¸ì˜¬ ìµœëŒ€ ê°œìˆ˜

    Returns:
        List of trending repositories
    """
    url = f"https://github.com/trending/{language}?since=daily"

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }

    try:
        print(f"ğŸ” GitHub Trending í¬ë¡¤ë§ ì‹œì‘: {url}")
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')

        # íŠ¸ë Œë”© ë ˆí¬ì§€í† ë¦¬ ëª©ë¡ ì°¾ê¸°
        articles = soup.find_all('article', class_='Box-row')

        trends = []
        for idx, article in enumerate(articles[:limit]):
            try:
                # ë ˆí¬ì§€í† ë¦¬ ì´ë¦„
                h2 = article.find('h2', class_='h3')
                if not h2:
                    continue

                repo_link = h2.find('a')
                if not repo_link:
                    continue

                repo_name = repo_link.get('href', '').strip('/')
                repo_url = f"https://github.com{repo_link.get('href', '')}"

                # ì„¤ëª…
                description_elem = article.find('p', class_='col-9')
                description = description_elem.text.strip() if description_elem else ""

                # ì–¸ì–´
                language_elem = article.find('span', attrs={'itemprop': 'programmingLanguage'})
                language = language_elem.text.strip() if language_elem else "Unknown"

                # ë³„(stars) ìˆ˜
                stars_elem = article.find('svg', class_='octicon-star')
                stars = 0
                if stars_elem:
                    stars_parent = stars_elem.find_parent('a')
                    if stars_parent:
                        stars_text = stars_parent.text.strip().replace(',', '')
                        try:
                            stars = int(stars_text.split()[0]) if stars_text else 0
                        except:
                            stars = 0

                # ì˜¤ëŠ˜ ì¶”ê°€ëœ ë³„ ìˆ˜
                stars_today_elem = article.find('span', class_='d-inline-block')
                stars_today = 0
                if stars_today_elem:
                    stars_today_text = stars_today_elem.text.strip()
                    if 'stars today' in stars_today_text or 'stars' in stars_today_text:
                        try:
                            stars_today = int(stars_today_text.replace(',', '').split()[0])
                        except:
                            stars_today = 0

                # í¬í¬ ìˆ˜
                forks = 0
                forks_elem = article.find('svg', class_='octicon-repo-forked')
                if forks_elem:
                    forks_parent = forks_elem.find_parent('a')
                    if forks_parent:
                        forks_text = forks_parent.text.strip().replace(',', '')
                        try:
                            forks = int(forks_text.split()[0]) if forks_text else 0
                        except:
                            forks = 0

                trend = {
                    'title': repo_name,
                    'description': description,
                    'url': repo_url,
                    'category': language,
                    'rank': idx + 1,
                    'metadata': {
                        'stars': stars,
                        'stars_today': stars_today,
                        'forks': forks,
                        'language': language
                    }
                }

                trends.append(trend)
                print(f"âœ… [{idx + 1}] {repo_name} - â­ {stars} (+{stars_today} today)")

            except Exception as e:
                print(f"âš ï¸  í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                continue

        print(f"âœ… ì´ {len(trends)}ê°œì˜ íŠ¸ë Œë”© ë ˆí¬ì§€í† ë¦¬ ìˆ˜ì§‘ ì™„ë£Œ")
        return trends

    except requests.RequestException as e:
        print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}")
        raise
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        raise


def test_scraper():
    """í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("GitHub Trending í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    trends = scrape_github_trending(limit=5)

    print(f"\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:")
    for trend in trends:
        print(f"\nì œëª©: {trend['title']}")
        print(f"ì„¤ëª…: {trend['description'][:100]}...")
        print(f"ì–¸ì–´: {trend['category']}")
        print(f"ë³„: {trend['metadata']['stars']} (+{trend['metadata']['stars_today']} today)")

    return trends


if __name__ == "__main__":
    test_scraper()
